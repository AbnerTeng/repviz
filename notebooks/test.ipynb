{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from alive_progress import alive_it\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.datasets import fetch_covtype\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from src.hooks import HookManager\n",
    "from src.utils import list_child_modules\n",
    "\n",
    "\n",
    "class SampleDataset(Dataset):\n",
    "    def __init__(self, features: np.ndarray, label: np.ndarray) -> None:\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "        self.label = label\n",
    "        self._scaler()\n",
    "\n",
    "    def _scaler(self) -> None:\n",
    "        mm = MinMaxScaler()\n",
    "        self.features = mm.fit_transform(self.features)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.features.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        return (self.features[idx, :], self.label[idx] - 1)\n",
    "\n",
    "\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, n_feats: int, n_classes: int) -> None:\n",
    "        super().__init__()\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.LayerNorm(n_feats),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(n_feats, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, n_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.ffn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "ffn.0 LayerNorm((54,), eps=1e-05, elementwise_affine=True)\n",
      "ffn.1 Dropout(p=0.1, inplace=False)\n",
      "ffn.2 Linear(in_features=54, out_features=512, bias=True)\n",
      "ffn.3 ReLU()\n",
      "ffn.4 LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "ffn.5 Dropout(p=0.1, inplace=False)\n",
      "ffn.6 Linear(in_features=512, out_features=512, bias=True)\n",
      "ffn.7 ReLU()\n",
      "ffn.8 LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "ffn.9 Dropout(p=0.1, inplace=False)\n",
      "ffn.10 Linear(in_features=512, out_features=7, bias=True)\n",
      "ffn.11 Softmax(dim=1)\n",
      "on 0: Epoch: 1 | Loss: 1.958906238029503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "on 0: /var/folders/5p/5d5cjs1n0sd8dhmpcjd35h0r0000gn/T/ipykernel_34191/456188075.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "        torch.tensor(tr_x, dtype=torch.float32),\n",
      "      /var/folders/5p/5d5cjs1n0sd8dhmpcjd35h0r0000gn/T/ipykernel_34191/456188075.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "        torch.tensor(tr_y, dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|¸.·´¯`·.·´¯`·.¸¸.·´¯`·.¸.·´¯`·.·´¯`·.¸¸.| 1/1 [100%] in 17.5s (0.06/s) \n",
      "testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5p/5d5cjs1n0sd8dhmpcjd35h0r0000gn/T/ipykernel_34191/456188075.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ts_x = torch.tensor(ts_x, dtype=torch.float32)\n",
      "/var/folders/5p/5d5cjs1n0sd8dhmpcjd35h0r0000gn/T/ipykernel_34191/456188075.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ts_y = torch.tensor(ts_y, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.043105599683312824\n"
     ]
    }
   ],
   "source": [
    "cov_type = fetch_covtype(data_home=\"../covertype\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cov_type.data, cov_type.target, test_size=0.2, random_state=42\n",
    ")\n",
    "train_dataset = SampleDataset(X_train, y_train)\n",
    "test_dataset = SampleDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "print(\"training...\")\n",
    "\n",
    "model = FFN(X_train.shape[1], len(set(y_train)))\n",
    "list_child_modules(model)\n",
    "\n",
    "n_epochs = 1\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model = FFN(X_train.shape[1], len(set(y_train)))\n",
    "\n",
    "for epoch in alive_it(range(n_epochs), bar=\"fish\"):\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "    for tr_x, tr_y in train_loader:\n",
    "        tr_x, tr_y = (\n",
    "            torch.tensor(tr_x, dtype=torch.float32),\n",
    "            torch.tensor(tr_y, dtype=torch.long),\n",
    "        )\n",
    "        pred_tr_y = model(tr_x)\n",
    "        loss = criterion(pred_tr_y, tr_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch: {epoch + 1} | Loss: {epoch_loss / len(train_loader)}\")\n",
    "\n",
    "print(\"testing...\")\n",
    "model.eval()\n",
    "hook_mgr = HookManager()\n",
    "hook_mgr.register_hooks(model, partial_matches=None)\n",
    "\n",
    "with torch.no_grad():\n",
    "    preds = []\n",
    "\n",
    "    for ts_x, ts_y in test_loader:\n",
    "        ts_x = torch.tensor(ts_x, dtype=torch.float32)\n",
    "        ts_y = torch.tensor(ts_y, dtype=torch.long)\n",
    "        pred_y_test = model(ts_x)\n",
    "        preds.append(pred_y_test)\n",
    "\n",
    "    print(\n",
    "        f\"Accuracy: {np.sum(np.argmax(np.array(preds)[:, 0, :], axis=1) == y_test).item() / len(y_test)}\"\n",
    "    )\n",
    "\n",
    "activations = hook_mgr.get_activations()\n",
    "# print(activations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Stats for ffn.0:\n",
      "  mean: -0.0000\n",
      "  std: 0.9999\n",
      "  min: -0.4870\n",
      "  max: 2.8785\n",
      "  sparsity: 0.0000\n",
      "  skewness: 1.8789\n",
      "  kurtosis: 2.0993\n",
      "\n",
      " Stats for ffn.1:\n",
      "  mean: -0.0000\n",
      "  std: 0.9999\n",
      "  min: -0.4870\n",
      "  max: 2.8785\n",
      "  sparsity: 0.0000\n",
      "  skewness: 1.8789\n",
      "  kurtosis: 2.0993\n",
      "\n",
      " Stats for ffn.2:\n",
      "  mean: -0.0055\n",
      "  std: 0.5766\n",
      "  min: -1.6163\n",
      "  max: 1.7567\n",
      "  sparsity: 0.0000\n",
      "  skewness: 0.1820\n",
      "  kurtosis: -0.0047\n",
      "\n",
      " Stats for ffn.3:\n",
      "  mean: 0.2253\n",
      "  std: 0.3476\n",
      "  min: 0.0000\n",
      "  max: 1.7567\n",
      "  sparsity: 0.5000\n",
      "  skewness: 1.7828\n",
      "  kurtosis: 2.8011\n",
      "\n",
      " Stats for ffn.4:\n",
      "  mean: -0.0000\n",
      "  std: 1.0000\n",
      "  min: -0.6482\n",
      "  max: 4.4047\n",
      "  sparsity: 0.0000\n",
      "  skewness: 1.7828\n",
      "  kurtosis: 2.8011\n",
      "\n",
      " Stats for ffn.5:\n",
      "  mean: -0.0000\n",
      "  std: 1.0000\n",
      "  min: -0.6482\n",
      "  max: 4.4047\n",
      "  sparsity: 0.0000\n",
      "  skewness: 1.7828\n",
      "  kurtosis: 2.8011\n",
      "\n",
      " Stats for ffn.6:\n",
      "  mean: -0.0097\n",
      "  std: 0.5436\n",
      "  min: -1.5103\n",
      "  max: 1.5893\n",
      "  sparsity: 0.0000\n",
      "  skewness: -0.0666\n",
      "  kurtosis: -0.0989\n",
      "\n",
      " Stats for ffn.7:\n",
      "  mean: 0.2124\n",
      "  std: 0.3091\n",
      "  min: 0.0000\n",
      "  max: 1.5893\n",
      "  sparsity: 0.5000\n",
      "  skewness: 1.5913\n",
      "  kurtosis: 2.0254\n",
      "\n",
      " Stats for ffn.8:\n",
      "  mean: 0.0000\n",
      "  std: 0.9999\n",
      "  min: -0.6872\n",
      "  max: 4.4540\n",
      "  sparsity: 0.0000\n",
      "  skewness: 1.5913\n",
      "  kurtosis: 2.0254\n",
      "\n",
      " Stats for ffn.9:\n",
      "  mean: 0.0000\n",
      "  std: 0.9999\n",
      "  min: -0.6872\n",
      "  max: 4.4540\n",
      "  sparsity: 0.0000\n",
      "  skewness: 1.5913\n",
      "  kurtosis: 2.0254\n",
      "\n",
      " Stats for ffn.10:\n",
      "  mean: -0.4190\n",
      "  std: 0.7457\n",
      "  min: -1.7615\n",
      "  max: 0.5950\n",
      "  sparsity: 0.0000\n",
      "  skewness: -0.2831\n",
      "  kurtosis: -0.7378\n",
      "\n",
      " Stats for ffn.11:\n",
      "  mean: 0.1429\n",
      "  std: 0.0956\n",
      "  min: 0.0290\n",
      "  max: 0.3063\n",
      "  sparsity: 0.0000\n",
      "  skewness: 0.6572\n",
      "  kurtosis: -1.0705\n"
     ]
    }
   ],
   "source": [
    "from src.statistics import print_summary\n",
    "\n",
    "for k, v in activations.items():\n",
    "    print_summary(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffn.0 LayerNorm((54,), eps=1e-05, elementwise_affine=True)\n",
      "ffn.1 Dropout(p=0.1, inplace=False)\n",
      "ffn.2 Linear(in_features=54, out_features=512, bias=True)\n",
      "ffn.3 ReLU()\n",
      "ffn.4 LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "ffn.5 Dropout(p=0.1, inplace=False)\n",
      "ffn.6 Linear(in_features=512, out_features=512, bias=True)\n",
      "ffn.7 ReLU()\n",
      "ffn.8 LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "ffn.9 Dropout(p=0.1, inplace=False)\n",
      "ffn.10 Linear(in_features=512, out_features=7, bias=True)\n",
      "ffn.11 Softmax(dim=1)\n"
     ]
    }
   ],
   "source": [
    "list_child_modules(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
